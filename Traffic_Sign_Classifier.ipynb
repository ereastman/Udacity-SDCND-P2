{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Visualize the German Traffic Signs Dataset. This is open ended, some suggestions include: plotting traffic signs images, plotting the count of each sign, etc. Be creative!\n",
    "\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- features -> the images pixel values, (width, height, channels)\n",
    "- labels -> the label of the traffic sign\n",
    "- sizes -> the original width and height of the image, (width, height)\n",
    "- coords -> coordinates of a bounding box around the sign in the image, (x1, y1, x2, y2). Based the original image (not the resized version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = \"traffic-sign-data/train.p\"\n",
    "testing_file = \"traffic-sign-data/test.p\"\n",
    "valid_file = \"traffic-sign-data/valid.p\"\n",
    "with open(training_file, mode='rb') as f:\n",
    "    X_extended_train=None\n",
    "    X_train_orig = None\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open(valid_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "with open(\"signnames.csv\", mode='rb') as f:\n",
    "    #sign_nums, sign_names = np.loadtxt(f, skiprows=1, delimiter=',', dtype=[np.uint8, np.str_], unpack=True)\n",
    "    classnames = np.genfromtxt(f, delimiter=\",\", \\\n",
    "                              dtype=[('myint','i'), ('mystring','S50')], \\\n",
    "                              skip_header=1, usecols=(0,1))\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Basic data summary.\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "n_valid = len(X_valid)\n",
    "_, height, width, channel = X_train.shape\n",
    "image_shape = (height, width, channel)\n",
    "n_classes = len(classnames)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "# augment single image by applying flips, rotations to select image classes\n",
    "X_extended_train = None\n",
    "def select_flipping(images, labels):\n",
    "\n",
    "    X=images\n",
    "    y=labels\n",
    "    # Classes of signs that, when flipped horizontally, should still be classified as the same class\n",
    "    self_flippable_horizontally = np.array([11, 12, 13, 15, 17, 18, 22, 26, 30, 35])\n",
    "    # Classes of signs that, when flipped vertically, should still be classified as the same class\n",
    "    self_flippable_vertically = np.array([1, 5, 12, 15, 17])\n",
    "    # Classes of signs that, when flipped horizontally and then vertically, should still be classified as the same class\n",
    "    self_flippable_both = np.array([32, 40])\n",
    "    # Classes of signs that, when flipped horizontally, would still be meaningful, but should be classified as some other class\n",
    "    cross_flippable = np.array([\n",
    "        [19, 20],\n",
    "        [33, 34],\n",
    "        [36, 37],\n",
    "        [38, 39],\n",
    "        [20, 19],\n",
    "        [34, 33],\n",
    "        [37, 36],\n",
    "        [39, 38],\n",
    "    ])\n",
    "    n_classes = 43\n",
    "\n",
    "    X_extended = np.empty([0, X.shape[1], X.shape[2], X.shape[3]], dtype=np.float32)\n",
    "    y_extended = np.empty([0], dtype=np.int32)\n",
    "    y_inds = np.empty([0], dtype=np.int32)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        # First copy existing data for this class\n",
    "        X_extended = np.append(X_extended, X[y == c], axis=0)\n",
    "        y_extended = np.append(y_extended, y[y==c], axis=0)\n",
    "        y_tb_app, = np.where(y==c)\n",
    "        y_inds = np.append(y_inds, np.ones([np.sum(y==c)])*-1, axis=0)\n",
    "        \n",
    "        # If we can flip images of this class horizontally and they would still belong to said class...\n",
    "        if c in self_flippable_horizontally:\n",
    "            # ...Copy their flipped versions into extended array.\n",
    "            X_extended = np.append(X_extended, X[y == c][:, :, ::-1, :], axis=0)\n",
    "            y_inds = np.append(y_inds, y_tb_app, axis=0)\n",
    "            y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype=np.int32))\n",
    "            if(y_inds.shape != y_extended.shape):\n",
    "                print(\"sfh\")\n",
    "                print(c)\n",
    "                break\n",
    "        \n",
    "        # If we can flip images of this class horizontally and they would belong to other class...\n",
    "        if c in cross_flippable[:, 0]:\n",
    "            # ...Copy flipped images of that other class to the extended array.\n",
    "            flip_class = cross_flippable[cross_flippable[:, 0] == c][0][1]\n",
    "            X_extended = np.append(X_extended, X[y == flip_class][:, :, ::-1, :], axis=0)\n",
    "            flipped_orig_label_inds, = np.where(y == flip_class)\n",
    "            y_inds = np.append(y_inds, flipped_orig_label_inds, axis=0)\n",
    "            # Fill labels for added images set to current class.\n",
    "            y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype=np.int32))\n",
    "            if(y_inds.shape != y_extended.shape):\n",
    "                print(\"cf\")\n",
    "                print(c)\n",
    "                break\n",
    "        \n",
    "        # If we can flip images of this class vertically and they would still belong to said class...\n",
    "        if c in self_flippable_vertically:\n",
    "            # ...Copy their flipped versions into extended array.\n",
    "            X_extended = np.append(X_extended, X[y == c][:, ::-1, :, :], axis=0)\n",
    "            y_inds = np.append(y_inds, y_tb_app, axis=0)\n",
    "            y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype=np.int32))\n",
    "            if(y_inds.shape != y_extended.shape):\n",
    "                print(\"sfv\")\n",
    "                print(c)\n",
    "                break\n",
    "    \n",
    "        # If we can flip images of this class horizontally AND vertically and they would still belong to said class...\n",
    "        if c in self_flippable_both:\n",
    "            # ...Copy their flipped versions into extended array.\n",
    "            X_extended = np.append(X_extended, X_extended[y_extended == c][:, ::-1, ::-1, :], axis=0)\n",
    "            y_inds = np.append(y_inds, y_tb_app, axis=0)\n",
    "            y_extended = np.append(y_extended, np.full((X_extended.shape[0] - y_extended.shape[0]), c, dtype=np.int32))\n",
    "            if(y_inds.shape != y_extended.shape):\n",
    "                print(\"sfb\")\n",
    "                print(c)\n",
    "                break\n",
    "    \n",
    "        \n",
    "    extend_datas  = X_extended\n",
    "    extend_labels = y_extended\n",
    "    return (extend_datas, extend_labels, y_inds)\n",
    "\n",
    "\n",
    "# use opencv to do data agumentation via perturbation (translation, rotation, brightness, saturation, contrast)\n",
    "# see also: https://github.com/dmlc/mxnet/blob/master/python/mxnet/image.py\n",
    "\n",
    "def perturb_set(images, keep=0):\n",
    "    return [perturb(im, keep) for im in images]\n",
    "    \n",
    "#def perturb(image, angle_limit=15, scale_limit=0.1, translate_limit=3, distort_limit=3, illumin_limit=0.2):\n",
    "def perturb(image, keep=0, angle_limit=15, scale_limit=0.1, translate_limit=3, distort_limit=3, illumin_limit=0.2):\n",
    "\n",
    "    if(np.random.uniform() < keep):\n",
    "        return image\n",
    "    (W, H, C) = image.shape\n",
    "    center = np.array([W / 2., H / 2.])\n",
    "    da = np.random.uniform(low=-1, high=1) * angle_limit/180. * math.pi\n",
    "    scale = np.random.uniform(low=-1, high=1) * scale_limit + 1\n",
    "\n",
    "    # Use small angle approximation instead of sin/cos functions\n",
    "    cc = scale*(1 - (da*da)/2.)\n",
    "    ss = scale*da\n",
    "    rotation    = np.array([[cc, ss],[-ss,cc]])\n",
    "    translation = np.random.uniform(low=-1, high=1, size=(1,2)) * translate_limit\n",
    "    distort     = np.random.standard_normal(size=(4,2)) * distort_limit\n",
    "\n",
    "    pts1 = np.array([[0., 0.], [0., H], [W, H], [W, 0.]])\n",
    "    pts2 = np.matmul(pts1-center, rotation) + center  + translation\n",
    "\n",
    "    #add perspective noise\n",
    "    pts2 = pts2 + distort\n",
    "\n",
    "\n",
    "    #http://milindapro.blogspot.jp/2015/05/opencv-filters-copymakeborder.html\n",
    "    matrix  = cv2.getPerspectiveTransform(pts1.astype(np.float32), pts2.astype(np.float32)) \n",
    "    perturb = cv2.warpPerspective(image, matrix, (W, H), flags=cv2.INTER_LINEAR,\n",
    "                                  borderMode=cv2.BORDER_REFLECT_101)  # BORDER_WRAP  #BORDER_REFLECT_101  #cv2.BORDER_CONSTANT  BORDER_REPLICATE\n",
    "\n",
    "    #brightness, contrast, saturation-------------\n",
    "    #from mxnet code\n",
    "    if 1:  #brightness\n",
    "        alpha = 1.0 + illumin_limit*np.random.uniform(-1, 1)\n",
    "        #alpha = 1.0 + illumin_limit*-1\n",
    "        perturb = perturb * alpha\n",
    "        perturb = np.clip(perturb,0.,255.)\n",
    "        pass\n",
    "\n",
    "    coef = np.array([[[0.299, 0.587, 0.114]]]) #rgb to gray (YCbCr) :  Y = 0.299R + 0.587G + 0.114B\n",
    "\n",
    "    if 1:  #contrast\n",
    "        alpha = illumin_limit*np.random.uniform(-1, 1)\n",
    "        #alpha = illumin_limit*-1\n",
    "        gray = perturb * coef\n",
    "        gray = (3.0 * (alpha) / gray.size) * np.sum(gray)\n",
    "        perturb = perturb * (1.0 + alpha)\n",
    "        perturb += gray\n",
    "        perturb = np.clip(perturb,0.,255.)\n",
    "        pass\n",
    "\n",
    "    if 1:  #saturation\n",
    "        alpha = illumin_limit*np.random.uniform(-1, 1)\n",
    "        #alpha = illumin_limit*-1\n",
    "        gray = perturb * coef\n",
    "        gray = np.sum(gray, axis=2, keepdims=True)\n",
    "        gray *= alpha\n",
    "        perturb = perturb * (1.0 + alpha)\n",
    "        perturb += gray\n",
    "        perturb = np.clip(perturb,0.,255.)\n",
    "        pass\n",
    "\n",
    "    return perturb\n",
    "\n",
    "def insert_subimage(image, sub_image, y, x): \n",
    "    h, w, c = sub_image.shape\n",
    "    image[y:y+h, x:x+w, :]=sub_image \n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#count\n",
    "#h = np.histogram(train_labels, bins=np.arange(num_class))\n",
    "#results image\n",
    "if X_extended_train is None:\n",
    "    X_extended_train, y_extended_train, y_extended_orig_inds = select_flipping(X_train, y_train)\n",
    "\n",
    "num_sample=10\n",
    "results_image = 255.*np.ones(shape=(n_classes*height,(num_sample+2+22)*width, channel),dtype=np.float32)\n",
    "for c in range(n_classes):\n",
    "    \n",
    "    #make mean\n",
    "    idx = list(np.where(y_train == c)[0])\n",
    "    mean_image = np.average(X_train[idx], axis=0)\n",
    "    insert_subimage(results_image, mean_image, c*height, width)\n",
    "\n",
    "    ### make random sample from original\n",
    "    #sample_im_inds = np.random.choice(idx, num_sample)\n",
    "    #perturbed_sample_ims = perturb_set(X_train[sample_im_inds])\n",
    "    ### make random sample from extended\n",
    "    idx_ext = list(np.where((y_extended_train == c) & (y_extended_orig_inds != 0))[0])\n",
    "    if(len(idx_ext) == 0):\n",
    "        idx_ext = list(np.where(y_train == c)[0])\n",
    "    ###\n",
    "    \n",
    "    sample_im_inds = np.random.choice(idx_ext, num_sample)\n",
    "    perturbed_sample_ims = perturb_set(X_extended_train[sample_im_inds])\n",
    "    \n",
    "    i = 0\n",
    "    for im in perturbed_sample_ims:\n",
    "        insert_subimage(results_image, im, c*height, (2+i)*width)\n",
    "        i = i+1\n",
    "\n",
    "    #print summary\n",
    "    count=len(idx_ext)\n",
    "    percentage = float(count)/float(len(X_extended_train))\n",
    "    cv2.putText(results_image, '%02d:%-6s'%(c, classnames[c]), ((2+num_sample)*width, int((c+0.7)*height)),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1)\n",
    "    cv2.putText(results_image, '[%4d]'%(count), ((2+num_sample+14)*width+40, int((c+0.7)*height)),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1)\n",
    "    \n",
    "\n",
    "print(\"////\")\n",
    "#imshow('results_image',results_image)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "\n",
    "print('** training data summary **')\n",
    "print('\\t1st column: label(image)')\n",
    "print('\\t2nd column: mean image')\n",
    "print('\\tother column: example images')\n",
    "print('\\tblack text: label')\n",
    "print('\\tblue text: sanple count for each class and histogram plot')\n",
    "plt.rcParams[\"figure.figsize\"] = (25,25)\n",
    "plt.imshow(results_image.astype(np.uint8))\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of the count of the number of examples of each sign\n",
    "# in the test set\n",
    "data = y_train\n",
    "\n",
    "fig, ax0 = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "d = np.diff(np.unique(data)).min()\n",
    "left_of_first_bin = data.min() - float(d)/2\n",
    "right_of_last_bin = data.max() + float(d)/2\n",
    "colors = ['red', 'lime']\n",
    "labels=['Original', 'Extended']\n",
    "ax0.legend(prop={'size': 10})\n",
    "ax0.set_title('bars with legend')\n",
    "ax0.hist([y_train, y_extended_train], np.arange(left_of_first_bin, right_of_last_bin + d, d), normed=True, color=colors, label=labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"STD of original: \", np.std(y_train))\n",
    "print(\"STD of extended: \", np.std(y_extended_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shuffle training examples\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "if X_train_orig is None:\n",
    "    print(len(y_train), len(y_extended_train))\n",
    "    X_train_orig, y_train_orig = X_train, y_train\n",
    "    X_train, y_train = X_extended_train, y_extended_train\n",
    "\n",
    "print(len(y_train_orig), len(y_train))    \n",
    "X_train, y_train, y_extended_orig_inds = shuffle(X_train, y_train, y_extended_orig_inds, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 Preprocess Data (includes shuffling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. If you generated additional data, why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "\n",
    "# tf Graph input\n",
    "keep_prob_conv = tf.placeholder(tf.float32)\n",
    "keep_prob_fc   = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(\"float\", [None, 32, 32, 3])\n",
    "\n",
    "y_rawlabels = tf.placeholder(\"int32\", [None])\n",
    "y = tf.one_hot(y_rawlabels, depth=43, on_value=1., off_value=0., axis=-1)\n",
    "\n",
    "# Transformations\n",
    "\n",
    "def flatten(x):\n",
    "    x_shape = x.get_shape().as_list()\n",
    "    new_shape = ft.reduce(lambda i,j: i*j, x_shape[1:])\n",
    "    return tf.reshape(x, [-1, new_shape])\n",
    "    \n",
    "# Activation Functions\n",
    "\n",
    "# ReLU = tf.nn.relu\n",
    "# tanh = tf.tanh\n",
    "# pReLU = parametric_relu\n",
    "def parametric_relu(x, weights):\n",
    "    pos = tf.nn.relu(x)\n",
    "    neg = tf.multiply(weights, tf.multiply(tf.subtract(x, tf.abs(x)), 0.5))\n",
    "\n",
    "    return tf.add(pos, neg)\n",
    "\n",
    "def conv2d(x, W, b, strides=3, name='conv'):\n",
    "    \"\"\"Conv2D wrapper, with bias and relu activation\"\"\"\n",
    "    # strides = [batch, in_height, in_width, channels]\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME', name=name)\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return x\n",
    "\n",
    "\n",
    "def skip_conv2d(x, weights, biases, epsilon=1e-3, name='skipper', strides=1):\n",
    "    tbr=x\n",
    "    for i in range(0,len(weights)):\n",
    "        print(\"  \", i)\n",
    "        tb_con = conv2d(x=tbr, W=weights[i], b=biases[i], strides=strides, name=name+'_%d'%i)\n",
    "        print(\"    Should be equal (input to conv shape): \", tbr.get_shape().as_list(), tb_con.get_shape().as_list())\n",
    "        print(\"    Weights and biases: \", weights[i].get_shape().as_list(), biases[i].get_shape().as_list())\n",
    "        tb_con = bn(tb_con, epsilon)\n",
    "        tb_con = tf.nn.relu(tb_con)\n",
    "        tbr = concat(tbr, tb_con)\n",
    "    return tbr\n",
    "\n",
    "def residual_unit(x, weights, biases, epsilon=1e-3, name='resid', strides=1):\n",
    "    print(\"  \", x.get_shape().as_list())\n",
    "    tb_con1 = conv2d(x=x, W=weights[0], b=biases[0], strides=strides, name=name+'_1')\n",
    "    tb_con1 = bn(tb_con1, epsilon)\n",
    "    tb_con1 = tf.nn.relu(tb_con1)\n",
    "    print(\"  \", tb_con1.get_shape().as_list())\n",
    "    tb_con2 = conv2d(x=tb_con1, W=weights[1], b=biases[1], strides=strides, name=name+'_2')\n",
    "    tb_con2 = bn(tb_con2, epsilon)\n",
    "    tb_con2 = tf.nn.relu(tb_con2)\n",
    "    print(\"  \", tb_con2.get_shape().as_list())\n",
    "    return tf.add(x, tb_con2)\n",
    "        \n",
    "\n",
    "def maxpool2d(x, k=2, strides=1, padding_setting='SAME'):\n",
    "    \"\"\"MaxPool2D wrapper.\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, strides, strides, 1],\n",
    "                          padding=padding_setting)\n",
    "\n",
    "def bn(x, epsilon=1e-3, offset=None, scale=None):\n",
    "    mean, var = tf.nn.moments(x,[0])\n",
    "    return tf.nn.batch_normalization(x, mean, var, offset, scale, epsilon)\n",
    "\n",
    "### concatenate tensors along 3rd dimension \n",
    "def concat(x, y, name='cat'):\n",
    "    #? cat = tf.concat(axis=3, values=input, name=name)\n",
    "\n",
    "    cat = tf.concat(axis=3,values=[x,y])\n",
    "    return cat\n",
    "\n",
    "def weight_variable(shape, weight_mean, weight_stddev):\n",
    "    initial = tf.truncated_normal(shape, stddev=weight_stddev, mean=weight_mean)\n",
    "    # alt: tf.random_normal(shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, bias_mean):\n",
    "    initial = tf.constant(bias_mean, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def generate_filter_weights(num_layers=1, nb_filters=1, skip_filter_ratio=1):\n",
    "    tbr = []\n",
    "    in_num = nb_filters\n",
    "    for i in range(num_layers):\n",
    "        out_num = int(nb_filters*(skip_filter_ratio)**(i+1))\n",
    "        tbr.append([in_num, out_num])\n",
    "        in_num = in_num+out_num\n",
    "    return tbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def LeNet_test(x):    \n",
    "#     # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "#     _, H, W, C = x.get_shape().as_list()\n",
    "#     print(H, W, C)\n",
    "    \n",
    "#     mu = 0\n",
    "#     sigma = 0.1\n",
    "#     epsilon = 1e-3\n",
    "#     # Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6.\n",
    "#     conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "#     conv1_b = tf.Variable(tf.zeros(6))\n",
    "#     conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    \n",
    "#     # Regularization\n",
    "#     #conv1   = tf.nn.dropout(conv1, keep_prob=keep_prob_conv)\n",
    "#     l2 = tf.nn.l2_loss(conv1_W)\n",
    "\n",
    "#     # Activation.\n",
    "#     #ReLU\n",
    "#     #conv1 = tf.nn.relu(conv1)\n",
    "#     #parametric-ReLU\n",
    "#     conv1_prelu_W = tf.Variable(tf.random_uniform(shape=(28, 28, 6), minval=0.1, maxval=0.3))\n",
    "#     conv1 = parametric_relu(conv1, conv1_prelu_W)\n",
    "#     #tanh\n",
    "#     #conv1 = tf.tanh(conv1)\n",
    "    \n",
    "#     # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "#     #conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "#     conv1 = tf.nn.avg_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "#     # Layer 2: Convolutional. Output = 10x10x16.\n",
    "#     conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "#     conv2_b = tf.Variable(tf.zeros(16))\n",
    "#     conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "#     # Regularization\n",
    "#     #conv2   = tf.nn.dropout(conv2, keep_prob=keep_prob_conv)\n",
    "#     l2 = l2 + tf.nn.l2_loss(conv2_W)\n",
    "    \n",
    "    \n",
    "#     # Activation.\n",
    "#     #ReLU\n",
    "#     #conv2 = tf.nn.relu(conv2)\n",
    "#     #parametric-ReLU\n",
    "#     conv2_prelu_W = tf.Variable(tf.random_uniform(shape=(10, 10, 16), minval=0.1, maxval=0.3))\n",
    "#     conv2 = parametric_relu(conv2, conv2_prelu_W)\n",
    "#     #tanh\n",
    "#     #conv2 = tf.tanh(conv2)\n",
    "    \n",
    "#     # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "#     #conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "#     conv2 = tf.nn.avg_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "#     # Flatten. Input = 5x5x16. Output = 400.\n",
    "#     fc0   = flatten(conv2)\n",
    "    \n",
    "#     # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "#     fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "#     fc1_b = tf.Variable(tf.zeros(120))\n",
    "#     fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "#     # Regularization\n",
    "#     #fc1   = tf.nn.dropout(fc1, keep_prob=keep_prob_fc)\n",
    "#     l2 = l2 + tf.nn.l2_loss(fc1_W)\n",
    "    \n",
    "     \n",
    "#     # Activation.\n",
    "#     #ReLU\n",
    "#     #fc1    = tf.nn.relu(fc1)\n",
    "#     #parametric-ReLU\n",
    "#     fc1_prelu_W = tf.Variable(tf.random_uniform(shape=[120], minval=0.1, maxval=0.3))\n",
    "#     fc1 = parametric_relu(fc1, fc1_prelu_W)\n",
    "#     #tanh\n",
    "#     #fc1 = tf.tanh(fc1)\n",
    "    \n",
    "#     # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "#     fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "#     fc2_b  = tf.Variable(tf.zeros(84))\n",
    "#     fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "#     # Regularization\n",
    "#     #fc2   = tf.nn.dropout(fc2, keep_prob=keep_prob_fc)\n",
    "#     l2 = l2 + tf.nn.l2_loss(fc2_W)\n",
    "    \n",
    "#     # Activation.\n",
    "#     #ReLU\n",
    "#     #fc2    = tf.nn.relu(fc2)\n",
    "#     #parametric-ReLU\n",
    "#     fc2_prelu_W = tf.Variable(tf.random_uniform(shape=[84], minval=0.1, maxval=0.3))\n",
    "#     fc2 = parametric_relu(fc2, fc2_prelu_W)\n",
    "#     #tanh\n",
    "#     #fc2 = tf.tanh(fc2)\n",
    "    \n",
    "#     # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "#     fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "#     fc3_b  = tf.Variable(tf.zeros(43))\n",
    "#     logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "#     # Regularization\n",
    "#     #logits   = tf.nn.dropout(logits, keep_prob=keep_prob_fc)\n",
    "#     l2 = l2 + tf.nn.l2_loss(fc3_W)\n",
    "    \n",
    "#     return logits , l2\n",
    "\n",
    "# #conv_net_le_test = LeNet_test(x)\n",
    "# conv_net_le_test, l2 = LeNet_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def LeNet_test_deep(x):    \n",
    "#     # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "#     _, H, W, C = x.get_shape().as_list()\n",
    "#     print(H, W, C)\n",
    "    \n",
    "#     mu = 0\n",
    "#     sigma = 0.1\n",
    "#     epsilon = 1e-3\n",
    "#     nb_filters_1 = 12\n",
    "#     nb_filters_2 = 24\n",
    "#     nb_filters_3 = 48\n",
    "    \n",
    "#     # Layer 1.1: \n",
    "#     # Convolutional. Input = 32x32x3. Output = 32x32x6.\n",
    "#     conv1_W_1 = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, nb_filters_1), mean = mu, stddev = sigma))\n",
    "#     conv1_b_1 = tf.Variable(tf.zeros(nb_filters_1))\n",
    "#     conv1_1   = tf.nn.conv2d(x, conv1_W_1, strides=[1, 1, 1, 1], padding='VALID') + conv1_b_1\n",
    "#     # Batch Norm.\n",
    "#     conv1_1 = bn(conv1_1, epsilon)\n",
    "#     conv1_1   = tf.nn.relu(conv1_1)\n",
    "#     # Dropout\n",
    "#     conv1_1   = tf.nn.dropout(conv1_1, keep_prob=keep_prob_conv)\n",
    "#     # Layer 1.2: \n",
    "#     # Convolutional. Input = 32x32x6. Output = 32x32x6.\n",
    "#     conv1_W_2 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_1, nb_filters_1), mean = mu, stddev = sigma))\n",
    "#     conv1_b_2 = tf.Variable(tf.zeros(nb_filters_1))\n",
    "#     conv1_2   = tf.nn.conv2d(conv1_1, conv1_W_2, strides=[1, 1, 1, 1], padding='SAME') + conv1_b_2\n",
    "#     # Batch Norm.\n",
    "#     #conv1_2 = bn(conv1_2, epsilon)\n",
    "#     conv1_2   = tf.nn.relu(conv1_2)\n",
    "#     # Dropout\n",
    "#     conv1_2   = tf.nn.dropout(conv1_2, keep_prob=keep_prob_conv)\n",
    "#     # Layer 1.3: \n",
    "#     # Convolutional. Input = 32x32x6. Output = 32x32x6.\n",
    "#     conv1_W_3 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_1, nb_filters_1), mean = mu, stddev = sigma))\n",
    "#     conv1_b_3 = tf.Variable(tf.zeros(nb_filters_1))\n",
    "#     conv1_3   = tf.nn.conv2d(conv1_2, conv1_W_3, strides=[1, 1, 1, 1], padding='SAME') + conv1_b_3\n",
    "#     # Batch Norm.\n",
    "#     #conv1_2 = bn(conv1_2, epsilon)\n",
    "#     conv1_3   = tf.nn.relu(conv1_3)\n",
    "#     # Dropout\n",
    "#     conv1_3   = tf.nn.dropout(conv1_3, keep_prob=keep_prob_conv)\n",
    "    \n",
    "#     # Residuals\n",
    "#     conv1 = tf.add(conv1_3, conv1_1)\n",
    "#     # Activation.\n",
    "#     conv1_prelu_W = tf.Variable(tf.random_uniform(shape=(28, 28, nb_filters_1), minval=0.1, maxval=0.3))\n",
    "#     conv1 = parametric_relu(conv1, conv1_prelu_W)\n",
    "#     # Dense. Output = 28x28x(2*nb_filters_1)\n",
    "#     conv1 = tf.concat([conv1, conv1_2], axis=3)\n",
    "#     # Pooling. Input = 28x28x24. Output = 14x14x24.\n",
    "#     conv1 = tf.nn.avg_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    \n",
    "#     # Layer 2.1: \n",
    "#     # Convolutional. Output = 10x10x24.\n",
    "#     conv2_W_1 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_2, nb_filters_2), mean = mu, stddev = sigma))\n",
    "#     conv2_b_1 = tf.Variable(tf.zeros(nb_filters_2))\n",
    "#     conv2_1   = tf.nn.conv2d(conv1, conv2_W_1, strides=[1, 1, 1, 1], padding='VALID') + conv2_b_1\n",
    "#     conv2_1   = tf.nn.relu(conv2_1)\n",
    "#     # Dropout\n",
    "#     conv2_1   = tf.nn.dropout(conv2_1, keep_prob=keep_prob_conv)\n",
    "#     # Layer 2.2: \n",
    "#     # Convolutional. Output = 10x10x24.\n",
    "#     conv2_W_2 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_2, nb_filters_2), mean = mu, stddev = sigma))\n",
    "#     conv2_b_2 = tf.Variable(tf.zeros(nb_filters_2))\n",
    "#     conv2_2   = tf.nn.conv2d(conv2_1, conv2_W_2, strides=[1, 1, 1, 1], padding='SAME') + conv2_b_2\n",
    "#     conv2_2   = tf.nn.relu(conv2_2)\n",
    "#     # Dropout\n",
    "#     conv2_2   = tf.nn.dropout(conv2_2, keep_prob=keep_prob_conv)\n",
    "#     # Layer 2.3: \n",
    "#     # Convolutional. Output = 10x10x24.\n",
    "#     conv2_W_3 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_2, nb_filters_2), mean = mu, stddev = sigma))\n",
    "#     conv2_b_3 = tf.Variable(tf.zeros(nb_filters_2))\n",
    "#     conv2_3   = tf.nn.conv2d(conv2_2, conv2_W_3, strides=[1, 1, 1, 1], padding='SAME') + conv2_b_3\n",
    "#     conv2_3   = tf.nn.relu(conv2_3)\n",
    "#     # Dropout\n",
    "#     conv2_3   = tf.nn.dropout(conv2_3, keep_prob=keep_prob_conv)\n",
    "    \n",
    "#     # Residuals\n",
    "#     conv2 = tf.add(conv2_3, conv2_1)\n",
    "#     # Activation.\n",
    "#     conv2_prelu_W = tf.Variable(tf.random_uniform(shape=(10, 10, nb_filters_2), minval=0.1, maxval=0.3))\n",
    "#     conv2 = parametric_relu(conv2, conv2_prelu_W)\n",
    "#     # Dense. Output = 28x28x(2*nb_filters_2)\n",
    "#     conv2 = tf.concat([conv2, conv2_2], axis=3)\n",
    "    \n",
    "#     # Layer 3.1: \n",
    "#     # Convolutional. Output = 10x10x(2*nb_filters_3)\n",
    "#     conv3_W_1 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_3, nb_filters_3), mean = mu, stddev = sigma))\n",
    "#     conv3_b_1 = tf.Variable(tf.zeros(nb_filters_3))\n",
    "#     conv3_1   = tf.nn.conv2d(conv2, conv3_W_1, strides=[1, 1, 1, 1], padding='SAME') + conv3_b_1\n",
    "#     conv3_1   = tf.nn.relu(conv3_1)\n",
    "#     # Dropout\n",
    "#     conv3_1   = tf.nn.dropout(conv3_1, keep_prob=keep_prob_conv)\n",
    "#     # Layer 2.2: \n",
    "#     # Convolutional. Output = 10x10x16.\n",
    "#     conv3_W_2 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_3, nb_filters_3), mean = mu, stddev = sigma))\n",
    "#     conv3_b_2 = tf.Variable(tf.zeros(nb_filters_3))\n",
    "#     conv3_2   = tf.nn.conv2d(conv3_1, conv3_W_2, strides=[1, 1, 1, 1], padding='SAME') + conv3_b_2\n",
    "#     conv3_2   = tf.nn.relu(conv3_2)\n",
    "#     # Dropout\n",
    "#     conv3_2   = tf.nn.dropout(conv3_2, keep_prob=keep_prob_conv)\n",
    "#     # Layer 2.3: \n",
    "#     # Convolutional. Output = 10x10x16.\n",
    "#     conv3_W_3 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_3, nb_filters_3), mean = mu, stddev = sigma))\n",
    "#     conv3_b_3 = tf.Variable(tf.zeros(nb_filters_3))\n",
    "#     conv3_3   = tf.nn.conv2d(conv3_2, conv3_W_3, strides=[1, 1, 1, 1], padding='SAME') + conv3_b_3\n",
    "#     conv3_3   = tf.nn.relu(conv3_3)\n",
    "#     # Dropout\n",
    "#     conv3_3   = tf.nn.dropout(conv3_3, keep_prob=keep_prob_conv)\n",
    "    \n",
    "#     # Residuals\n",
    "#     conv3 = tf.add(conv3_3, conv3_1)\n",
    "#     # Activation.\n",
    "#     conv3_prelu_W = tf.Variable(tf.random_uniform(shape=(10, 10, nb_filters_3), minval=0.1, maxval=0.3))\n",
    "#     conv3 = parametric_relu(conv3, conv3_prelu_W)\n",
    "#     # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "#     conv3 = tf.nn.avg_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "#     # Flatten. Input = 5x5xnb_filters_n. Output = 400.\n",
    "#     fc0   = flatten(conv3)\n",
    "#     nb_fc1_in = 5 * 5 * nb_filters_3\n",
    "    \n",
    "#     # Layer 3: Fully Connected. Input = 400. Output = 240.\n",
    "#     fc1_W = tf.Variable(tf.truncated_normal(shape=(nb_fc1_in, 240), mean = mu, stddev = sigma))\n",
    "#     fc1_b = tf.Variable(tf.zeros(240))\n",
    "#     fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "#     # Dropout\n",
    "#     fc1   = tf.nn.dropout(fc1, keep_prob=keep_prob_fc) \n",
    "#     # Activation.\n",
    "#     fc1_prelu_W = tf.Variable(tf.random_uniform(shape=[240], minval=0.1, maxval=0.3))\n",
    "#     fc1 = parametric_relu(fc1, fc1_prelu_W)\n",
    "    \n",
    "#     # Layer 4: Fully Connected. Input = 240. Output = 120.\n",
    "#     fc2_W  = tf.Variable(tf.truncated_normal(shape=(240, 120), mean = mu, stddev = sigma))\n",
    "#     fc2_b  = tf.Variable(tf.zeros(120))\n",
    "#     fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "#     # Dropout\n",
    "#     fc2   = tf.nn.dropout(fc2, keep_prob=keep_prob_fc)\n",
    "#     # Activation.\n",
    "#     fc2_prelu_W = tf.Variable(tf.random_uniform(shape=[120], minval=0.1, maxval=0.3))\n",
    "#     fc2 = parametric_relu(fc2, fc2_prelu_W)\n",
    "    \n",
    "#     # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "#     fc3_W  = tf.Variable(tf.truncated_normal(shape=(120, 43), mean = mu, stddev = sigma))\n",
    "#     fc3_b  = tf.Variable(tf.zeros(43))\n",
    "#     logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "#     # L2-Regularization\n",
    "#     l2 = tf.nn.l2_loss(conv1_W_1) + tf.nn.l2_loss(conv1_W_2) + tf.nn.l2_loss(conv1_W_3)\n",
    "#     l2 = l2 + tf.nn.l2_loss(conv2_W_1) + tf.nn.l2_loss(conv2_W_2) + tf.nn.l2_loss(conv2_W_3)\n",
    "#     l2 = l2 + tf.nn.l2_loss(conv3_W_1) + tf.nn.l2_loss(conv3_W_2) + tf.nn.l2_loss(conv3_W_3)\n",
    "#     l2 = l2 + tf.nn.l2_loss(fc1_W)\n",
    "#     l2 = l2 + tf.nn.l2_loss(fc2_W)\n",
    "#     l2 = l2 + tf.nn.l2_loss(fc3_W)\n",
    "    \n",
    "#     return logits , l2\n",
    "\n",
    "# #conv_net_le_test = LeNet_test(x)\n",
    "# conv_net_le_deep, l2 = LeNet_test_deep(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LeNet_test_final(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    _, H, W, C = x.get_shape().as_list()\n",
    "    print(H, W, C)\n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    epsilon = 1e-3\n",
    "    nb_filters_1 = 12\n",
    "    nb_filters_2 = 24\n",
    "    \n",
    "    # Layer 1.1: \n",
    "    # Convolutional. Input = 32x32x3. Output = 32x32x6.\n",
    "    conv1_W_1 = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, nb_filters_1), mean = mu, stddev = sigma))\n",
    "    conv1_b_1 = tf.Variable(tf.zeros(nb_filters_1))\n",
    "    conv1_1   = tf.nn.conv2d(x, conv1_W_1, strides=[1, 1, 1, 1], padding='VALID') + conv1_b_1\n",
    "    conv1_1   = tf.tanh(conv1_1)\n",
    "    # Dropout\n",
    "    conv1_1   = tf.nn.dropout(conv1_1, keep_prob=keep_prob_conv)\n",
    "    \n",
    "    # Pooling. Input = 28x28x24. Output = 14x14x24.\n",
    "    conv1 = tf.nn.avg_pool(conv1_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    \n",
    "    # Layer 2.1: \n",
    "    # Convolutional. Output = 10x10x24.\n",
    "    conv2_W_1 = tf.Variable(tf.truncated_normal(shape=(5, 5, nb_filters_1, nb_filters_2), mean = mu, stddev = sigma))\n",
    "    conv2_b_1 = tf.Variable(tf.zeros(nb_filters_2))\n",
    "    conv2_1   = tf.nn.conv2d(conv1, conv2_W_1, strides=[1, 1, 1, 1], padding='VALID') + conv2_b_1\n",
    "    conv2_1   = tf.tanh(conv2_1)\n",
    "    # Dropout\n",
    "    conv2_1   = tf.nn.dropout(conv2_1, keep_prob=keep_prob_conv)\n",
    "    \n",
    "    # Pooling. Input = 28x28x24. Output = 14x14x24.\n",
    "    conv2 = tf.nn.avg_pool(conv2_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Flatten. Input = 5x5xnb_filters_n. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    nb_fc1_in = 5 * 5 * nb_filters_2\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 240.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(nb_fc1_in, 240), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(240))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    # Dropout\n",
    "    fc1   = tf.nn.dropout(fc1, keep_prob=keep_prob_fc) \n",
    "    # Activation.\n",
    "    fc1 = tf.tanh(fc1)\n",
    "    \n",
    "    # Layer 4: Fully Connected. Input = 240. Output = 120.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(240, 120), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(120))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    # Dropout\n",
    "    fc2   = tf.nn.dropout(fc2, keep_prob=keep_prob_fc)\n",
    "    # Activation.\n",
    "    fc2 = tf.tanh(fc2)\n",
    "    \n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(120, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    # L2-Regularization\n",
    "    l2 = tf.nn.l2_loss(conv1_W_1)\n",
    "    l2 = l2 + tf.nn.l2_loss(conv2_W_1)\n",
    "    l2 = l2 + tf.nn.l2_loss(fc1_W)\n",
    "    l2 = l2 + tf.nn.l2_loss(fc2_W)\n",
    "    l2 = l2 + tf.nn.l2_loss(fc3_W)\n",
    "    \n",
    "    return logits , l2\n",
    "\n",
    "#conv_net_le_test = LeNet_test(x)\n",
    "conv_net_le_final, l2 = LeNet_test_final(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "References: \n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.4 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_uniform(images, labels, num_class, num_per_class):\n",
    "    X_tbr = np.empty([0, images.shape[1], images.shape[2], images.shape[3]], dtype=np.float32)\n",
    "    y_tbr = np.empty([0], dtype=np.int32)\n",
    "    for c in range(num_class):\n",
    "        idx_all, = np.where(labels == c)\n",
    "        idx = np.random.choice(idx_all, num_per_class)\n",
    "        X_tbr = np.append(X_tbr, images[idx], axis=0)\n",
    "        y_tbr = np.append(y_tbr, labels[idx], axis=0)\n",
    "    \n",
    "    return shuffle(X_tbr, y_tbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pred = conv_net_le_test\n",
    "pred = conv_net_le_final\n",
    "\n",
    "pred_probs = tf.nn.softmax(pred)\n",
    "anneal_steps = [6, 15, 30, training_epochs]\n",
    "pos = 0\n",
    "# Training parameters\n",
    "initial_learning_rate = 0.001\n",
    "lr = initial_learning_rate\n",
    "anneal_rate = 0.5\n",
    "batch_size = 128\n",
    "training_epochs = 50\n",
    "n_train = len(X_train) * 2\n",
    "num_per_class = int(n_train / n_classes)\n",
    "print(\"Training Parameters: \")\n",
    "print(\"  Initial Learning Rate: \", initial_learning_rate)\n",
    "print(\"  Batch Size: \", batch_size)\n",
    "print(\"  Epochs: \", training_epochs)\n",
    "print(\"  Training set size: \", n_train)\n",
    "print(\"  Number of classes per training set: \", num_per_class)\n",
    "display_step = 1\n",
    "\n",
    "# Define cost function and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y_rawlabels))\n",
    "\n",
    "# Regularization\n",
    "beta = 0.0005\n",
    "cost = cost + beta * l2\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Function to initialise the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "# Initialise variables\n",
    "sess.run(init)\n",
    "\n",
    "# Initialise time logs\n",
    "init_time = time.time()\n",
    "epoch_accuracies = []\n",
    "learning_rates = []\n",
    "current_acc = 0.0\n",
    "anneal_count = 0\n",
    "max_epoch_count = 3\n",
    "finish_count = 0\n",
    "max_no_change_count = 3\n",
    "req_change = 0.05\n",
    "print(\"Training...\")\n",
    "lr = initial_learning_rate\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1)) \n",
    "    arg_im, arg_lab = generate_uniform(X_train, y_train, num_class=n_classes, num_per_class=num_per_class) \n",
    "    arg_im = perturb_set(arg_im, keep=0.8)\n",
    "    #arg_lab = y_train\n",
    "    n_train = len(arg_im)\n",
    "    total_batch = int(n_train / batch_size)\n",
    "    # Loop over all batches\n",
    "    batch_avg = 0\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = np.array(arg_im[i * batch_size:(i + 1) * batch_size]), \\\n",
    "                           np.array(arg_lab[i * batch_size:(i + 1) * batch_size])\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y_rawlabels: batch_y, learning_rate: lr, keep_prob_conv: 0.8, keep_prob_fc: 0.9})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "        batch_avg += c\n",
    "        if((i+1) % 100 == 0):\n",
    "            #print(\"  Loss: \", batch_avg/100)\n",
    "            batch_avg=0\n",
    "        \n",
    "    # Display logs\n",
    "    if epoch % display_step == 0:\n",
    "        current_time = time.time()\n",
    "        print(\"  Time: \", current_time - init_time)\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        with sess.as_default():\n",
    "            epoch_accuracy = accuracy.eval({x: X_valid, y_rawlabels: y_valid, keep_prob_conv: 1, keep_prob_fc: 1})\n",
    "            print(\"  Accuracy (validation):\", epoch_accuracy)\n",
    "            epoch_accuracies.append(epoch_accuracy)\n",
    "            learning_rates.append(lr)\n",
    "            current_acc = np.mean(epoch_accuracies[-5:])\n",
    "            print(\"    5 Epoch Moving Average:\", current_acc)\n",
    "            \n",
    "    if epoch >= anneal_steps[pos]:\n",
    "        lr*=anneal_rate\n",
    "        print(\"New learning rate: \", lr)\n",
    "        pos+=1\n",
    "        \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "curr_time = time.time()\n",
    "training_time = curr_time - init_time\n",
    "\n",
    "# Test model\n",
    "y_rawpreds = tf.cast(tf.argmax(pred, 1), dtype=tf.int32)\n",
    "\n",
    "correct_prediction = tf.equal(y_rawpreds, y_rawlabels)\n",
    "# Calculate accuracy\n",
    "# accuracy_train = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "# print(\"Accuracy (train):\", accuracy_train.eval({x_unflattened: X_train, y_rawlabels: y_train}))\n",
    "train_predict_time = time.time()\n",
    "# print(\"Time to calculate accuracy on training set: \", train_predict_time - epoch_time)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(conf_arr, normed=True):\n",
    "    if normed:\n",
    "        norm_conf = conf_arr.astype('float') / conf_arr.sum(axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        norm_conf = conf_arr\n",
    "    fig = plt.figure()\n",
    "    plt.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                interpolation='nearest')\n",
    "\n",
    "    width, height = conf_arr.shape\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center')\n",
    "\n",
    "    cb = fig.colorbar(res)\n",
    "    alphabet = np.arange(width)\n",
    "    plt.xticks(range(width), alphabet[:width])\n",
    "    plt.yticks(range(height), alphabet[:height])\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('ConfusionMatrices/RES_LONG', format='png')\n",
    "\n",
    "def plot_accuracy_learningrate(epoch_accuracies, learning_rates):\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(2, sharex=True)\n",
    "    axarr[0].plot(range(len(epoch_accuracies)), epoch_accuracies, 'b-')\n",
    "    axarr[0].set_title('accuracy')\n",
    "    axarr[1].plot(range(len(learning_rates)), learning_rates, 'g-')\n",
    "    axarr[1].set_title('learning rate')\n",
    "    plt.show()\n",
    "    \n",
    "# Line below needed only when not using `with tf.Session() as sess`\n",
    "with sess.as_default():\n",
    "    train_predict_time = time.time()\n",
    "    [final_accuracy, y_pred, correct] = sess.run([accuracy, y_rawpreds, correct_prediction], \n",
    "                                                 feed_dict = {x: X_test, y_rawlabels: y_test, keep_prob_conv: 1, keep_prob_fc: 1})\n",
    "    current_time = time.time()\n",
    "    #print(\"Accuracy (test):\", accuracy.eval({x: X_test, y_rawlabels: y_test}))\n",
    "    print(\"Final Accuracy:\", final_accuracy)\n",
    "    print(\"Time to evaluate test set: \", current_time - train_predict_time)\n",
    "    print(\"Training Time: \", training_time)\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1-score:\", metrics.f1_score(y_test, y_pred, average='macro'))\n",
    "    conf_m = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion_matrix:\")\n",
    "    plot_confusion_matrix(conf_m, normed=True)\n",
    "    plot_accuracy_learningrate(epoch_accuracies, learning_rates)\n",
    "    #fpr, tpr, tresholds = metrics.roc_curve(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It would be helpful to plot the images in the notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "(Special characteristics of images are noted in the comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper function to read image copied from lane lines project\n",
    "def read_image_and_print_dims(image_path):\n",
    "    \"\"\"Reads and returns image.\n",
    "    Helper function to examine how an image is represented.\n",
    "    \"\"\"\n",
    "    #reading in an image\n",
    "    image = mpimg.imread(image_path)\n",
    "    #printing out some stats and plotting\n",
    "    print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "    plt.imshow(image)  #call as plt.imshow(gray, cmap='gray') to show a grayscaled image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This sign is not in English. It is a stop sign.\n",
    "# There are multiple signs in the picture. \n",
    "# What wil the model attempt to recognise?\n",
    "japanese_sign = read_image_and_print_dims('traffic-sign-data/japanese-sign.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# There is other intervening text in the image.\n",
    "# This sign is shown at an angle.\n",
    "german_sign = read_image_and_print_dims('traffic-sign-data/german-sign.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This sign is quite clear.\n",
    "two_way_sign = read_image_and_print_dims('traffic-sign-data/two-way-sign.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can the model recognise the 20 km/h sign as a speed limit sign\n",
    "# even though it has different background colour, different shape\n",
    "# and additional 'km/h' text?\n",
    "speed_limit_stop = read_image_and_print_dims('traffic-sign-data/speed-limit-stop.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What will the model think this is?\n",
    "shark_sign = read_image_and_print_dims('traffic-sign-data/shark-sign.jpg')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Crop signs\n",
    "japanese_sign_cropped = japanese_sign[0:160,25:185,:]\n",
    "plt.imshow(japanese_sign_cropped)\n",
    "german_sign_cropped = german_sign[:280,:280,:]\n",
    "plt.imshow(german_sign_cropped)\n",
    "two_way_sign_cropped = two_way_sign[:350,:350,:]\n",
    "plt.imshow(two_way_sign_cropped)\n",
    "speed_limit_stop_cropped = speed_limit_stop[450:850,200:600,:]\n",
    "plt.imshow(speed_limit_stop_cropped)\n",
    "shark_sign_cropped = shark_sign[:,:1298,:]\n",
    "plt.imshow(shark_sign_cropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "import cv2 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# shark_sign_cropped.reshape(28,28)\n",
    "def resize_to_32_32(sign_cropped):\n",
    "    \"\"\"Resizes square image to 32 x 32 pixels.\"\"\"\n",
    "    return cv2.resize(sign_cropped, (32, 32))\n",
    "\n",
    "japanese_sign_reshaped = resize_to_32_32(japanese_sign_cropped)\n",
    "german_sign_reshaped = resize_to_32_32(german_sign_cropped)\n",
    "two_way_sign_reshaped = resize_to_32_32(two_way_sign_cropped)\n",
    "speed_limit_stop_reshaped = resize_to_32_32(speed_limit_stop_cropped)\n",
    "shark_sign_reshaped = resize_to_32_32(shark_sign_cropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "def resize_and_save_square_image(image, image_name):\n",
    "    \"\"\"Resizes square image to 32 x 32 pixels and saves it as a PNG\n",
    "    with name `image_name.png`.\"\"\"\n",
    "    cv2.imwrite(\"traffic-sign-data/\" + image_name, cv2.resize(image, (32, 32)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Code used to save resized images to png files\n",
    "list_of_images = [japanese_sign_cropped, german_sign_cropped, \n",
    "                  two_way_sign_cropped, speed_limit_stop_cropped,\n",
    "                  shark_sign_cropped]\n",
    "resize_and_save_square_image(japanese_sign_cropped, \"japanese_sign_resized.png\")\n",
    "resize_and_save_square_image(german_sign_cropped, \"german_sign_resized.png\")\n",
    "resize_and_save_square_image(two_way_sign_cropped, \"two_way_sign_resized.png\")\n",
    "resize_and_save_square_image(speed_limit_stop_cropped, \"speed_limit_stop_resized.png\")\n",
    "resize_and_save_square_image(shark_sign_cropped, \"shark_sign_resized.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 The Model's Predictions on the New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "def predict(img):\n",
    "    \"\"\"Print model's prediction of which traffic sign this image is.\"\"\"\n",
    "    classification = sess.run(tf.argmax(pred, 1), feed_dict={x_unflattened: [img], dropout_conv: 1, dropout_fc: 1})\n",
    "    print(classification)\n",
    "    print('NN predicted', classification[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_and_pred_X_train(index):\n",
    "    \"\"\"Show image from training set and print model's prediction \n",
    "    (of which traffic sign this image is).\n",
    "    \"\"\"\n",
    "    plt.imshow(X_train[index])\n",
    "    predict(X_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_and_pred_image(image):\n",
    "    \"\"\"Show image and print model's prediction (of which traffic \n",
    "    sign this image is).\n",
    "    \"\"\"\n",
    "    plt.imshow(image)\n",
    "    predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_show_and_pred_image(image_path):\n",
    "    \"\"\"Read image, show image and print model's prediction (of \n",
    "    which traffic sign this image is).\n",
    "    \"\"\"\n",
    "    # Read in image from file\n",
    "    image = mpimg.imread(image_path)\n",
    "    # Show image\n",
    "    # Call as plt.imshow(gray, cmap='gray') to show a grayscaled image\n",
    "    plt.imshow(image) \n",
    "    predict(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "show_and_pred_X_train(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_show_and_pred_image_tsdata(image_name):\n",
    "    \"\"\"Read image from dir `traffic-sign-data`, show image and print model's prediction (of \n",
    "    which traffic sign this image is).\n",
    "    \"\"\"\n",
    "    return read_show_and_pred_image('traffic-sign-data/' + image_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "japanese_sign = read_show_and_pred_image_tsdata(\"japanese_sign_resized.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a Japanese stop sign, though it looks like a Yield sign.\n",
    "The network predicts this is a Roundabout Mandatory sign, which is completely different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "german_sign = read_show_and_pred_image_tsdata(\"german_sign_resized.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a no parking zone sign. The network predicts this is a 'Right-of-way at the next intersection' sign. They are not similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "two_way_sign = read_show_and_pred_image_tsdata(\"two_way_sign_resized.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The network predicts this is a Go straight or left sign. They are similar in that there precisely two curved arrows in both signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speed_limit_stop = read_show_and_pred_image_tsdata(\"speed_limit_stop_resized.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The network predicts this is a roundabout mandatory sign (40). This is wrong- it should be 20km/h speed limit (0). The network may have been confused by the many curves that make up the sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shark_sign = read_show_and_pred_image_tsdata(\"shark_sign_resized.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The network predicts this is a roundabout mandatory sign. This is wrong, but then there is no correct class within the 43 for this sign. \n",
    "* It is unclear why this sign should be the roundabout mandatory sign of all signs. \n",
    "    * There are not many curved arrows - the black portion of the sign is small and is close to a short horizontal line segment in the middle of the sign.\n",
    "    * The diamond-shaped sign could have indicated Priority Road (12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the dataset?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "(Answer applied to captured pictures)\n",
    "\n",
    "No, it does not perform equally well on captured images. It has a performance of 0% accuracy on captured images as opposed to 79% on the test set.\n",
    "\n",
    "* The images not included in the dataset are not exactly the same road signs so there is additional difficulty because the model needs to generalise well to classify these new signs correctly. The\n",
    "* Some road signs such as the shark sign may not even be included in the 43 categories.\n",
    "* The images are also processed (e.g. cropped) differently.\n",
    "\n",
    "It seems that the model is classifying 'unknown signs' as Roundabout Mandatory signs.\n",
    "\n",
    "Reference for images of correct German signage: http://www.gettingaroundgermany.info/zeichen.shtml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 Visualising the certainty of the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def certainty_of_predictions(img):\n",
    "    \"\"\"Return model's top five choices for what traffic sign \n",
    "    this image is and its confidence in its predictions.\n",
    "    \"\"\"\n",
    "    top_five = sess.run(tf.nn.top_k(tf.nn.softmax(pred), k=5), feed_dict={x_unflattened: [img], dropout_conv: 1, dropout_fc: 1})\n",
    "    print(\"Top five: \", top_five)\n",
    "    return top_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_and_pred_certainty_image(image):\n",
    "    plt.imshow(image)\n",
    "    return certainty_of_predictions(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_and_pred_certainty_X_train(index):\n",
    "    \"\"\"Show image from training set and print model's certainty of its \n",
    "    prediction (of which traffic sign this image is).\n",
    "    \"\"\"\n",
    "    plt.imshow(X_train[index])\n",
    "    return certainty_of_predictions(X_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sign_names = pd.read_csv(\"signnames.csv\")\n",
    "sign_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_certainty_arrays(probabilities, labels):\n",
    "    \"\"\"Plot model's probabilities (y) and traffic sign labels (x) \n",
    "    in a bar chart.\n",
    "    \"\"\"\n",
    "    y_pos = np.arange(len(labels))\n",
    "    performance = [10,8,6,4,2,1]\n",
    "\n",
    "    plt.bar(y_pos, probabilities, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, labels)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Traffic sign')\n",
    "    plt.title('Model\\'s certainty of its predictions')\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Traffic Sign Key\")\n",
    "    for label in labels:\n",
    "        print(label, \": \", sign_names.loc[label]['SignName'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_and_pred_certainty_X_train(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_certainty_arrays([ 1.,  0.,  0.,  0.,  0.], [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "japanese_sign_certainties = show_and_pred_certainty_image(japanese_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "japanese_sign_certainties[1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_certainty_arrays(japanese_sign_certainties[0][0],\n",
    "                      japanese_sign_certainties[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "german_sign_certainties = show_and_pred_certainty_image(german_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_certainty_arrays(german_sign_certainties[0][0], \n",
    "                      german_sign_certainties[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "two_way_sign_certainties = show_and_pred_certainty_image(two_way_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_certainty_arrays(two_way_sign_certainties[0][0], two_way_sign_certainties[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speed_limit_stop_certainties = show_and_pred_certainty_image(speed_limit_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_certainty_arrays(speed_limit_stop_certainties[0][0],\n",
    "                      speed_limit_stop_certainties[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shark_sign_certainties = show_and_pred_certainty_image(shark_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_certainty_arrays(shark_sign_certainties[0][0], shark_sign_certainties[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "(see code above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* The model is certain of all of its predictions even though some are wrong. \n",
    "* The model also predicts different outcomes confidently for the two times I ran the predictions on each sign. \n",
    "\n",
    "These are both strange outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**\n",
    "Not applicable at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Close the current session.\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
